<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="TIFA: Accurate and Interpretable Text-to-Image Faithfulness Evaluation with Question Answering">
  <meta name="keywords" content="Text-to-Image, Evaluation, VQA, GPT-3">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>TIFA</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/tifa.png">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://keunhong.com">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https:yushi-hu.github.io/promptcap_demo/">
            PromptCap
          </a>
        </div>
      </div>
    </div>

  </div>
</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title"><img src="static/images/tifa.png" alt="icon" style="width:80px; transform: translateY(20%);">TIFA: Accurate and Interpretable <br> Text-to-Image Faithfulness Evaluation <br> with Question Answering</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://yushi-hu.github.io/">Yushi Hu</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://https://liubl1217.github.io/">Benlin Liu</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://homes.cs.washington.edu/~jkasai/">Jungo Kasai</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://homes.cs.washington.edu/~yizhongw/">Yizhong Wang</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://people.ece.uw.edu/ostendorf/">Mari Ostendorf</a><sup>1</sup>
            </span>
              <span class="author-block">
                    <a href="http://www.ranjaykrishna.com/">Ranjay Krishna</a><sup>1</sup>
                    </span>
            <span class="author-block">
              <a href="http://nasmith.github.io/">Noah A. Smith</a><sup>1,2</sup>,
            </span>

          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>University of Washington,</span>
            <span class="author-block"><sup>2</sup>Allen Institute for AI</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/abs/2303.11897"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <!-- <span class="link-block">
                <a href="https://arxiv.org/pdf/2211.09699.pdf"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span> -->
              <!-- Video Link. -->
              
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/Yushi-Hu/tifa"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
              <span class="link-block">
                <a href="https://github.com/Yushi-Hu/tifa"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>TIFA v1.0 Text Inputs + Questions</span>
                  </a>
              </span>

      <span class="link-block">
        <a href="https://tifa-benchmark.github.io" class="external-link button is-normal is-rounded is-dark">
          <span class="icon">
            <i class="far fa-images"></i>
          </span>
          <span>TIFA v1.0 Leaderboard</span>
        </a>
      </span>


            </div>

                          

          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">

      <h2 class="subtitle has-text-centered">
        <span class="dnerf">TIFA</span> evaluates a synthesized image by asking and answering questions about it, utilizing the power of Large Language Models (now GPT-3) and Image-to-Text Models (now mPLUG, will be GPT-4).
      </h2>
      <img src="./static/images/tifa_webteaser.jpeg" alt="tifa teaser">
            <h2 class="subtitle has-text-centered">
              Step1: Generate a checklist of question-answer pairs with LLM (now GPT-3). <br>
              Step2: Check whether existing VQA models can answer these questions using the generated image.
            </h2>

      
    </div>
  </div>
</section>



<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Text-to-image generation models often fail to produce images that accurately align with the text inputs. We introduce <span style="color: red;"><b>TIFA (Text-to-image Faithfulness evaluation with question Answering)</b></span>, an automatic evaluation metric that measures the faithfulness of a generated image to its text input via <span style="color: red;"><b>visual question answering (VQA). </b></span>
          </p>
           <p>
            Specifically, given a text input, we automatically generate several question-answer pairs using a <span style="color: red;"><b>language model</b></span>. We calculate image faithfulness by checking whether existing VQA models can answer these questions using the generated image. TIFA is a reference-free metric that allows for <span style="color: red;"><b>fine-grained and interpretable</b></span> evaluations of generated images.TIFA also has better correlations with human judgments than existing metrics (CLIP and SPICE). 
          </p>
          
          <p>
            Based on this approach, we introduce <span style="color: red;"><b>TIFA v1.0</b></span>, a benchmark consisting of 4K diverse text inputs and 25K questions across 12 categories (object, counting, etc.). We present a comprehensive evaluation of existing text-to-image models using TIFA v1.0 and highlight the limitations and challenges of current models. For instance, we find that current text-to-image models, despite doing well on color and material, still <span style="color: red;"><b>struggle in counting, spatial relations, and composing multiple objects</b></span>. We hope our benchmark will help carefully measure the research progress in text-to-image synthesis and provide valuable insights for further research.
          </p>
          
        </div>
      </div>
    </div>
    <!--/ Abstract. -->


<section class="hero is-small">
  <div class="hero-body">
    <div class="container is-max-desktop is-centered has-text-centered">
      <h2 class="title is-3">Updates</h2>
      <div class="content has-text-justified">
        <p>
          Still under construction. Stay tuned! <br>
          Will include the following: More discussions, Benchmark, VQA modules, Question Generation modules (with OpenAI API and Flan-T5), HuggingFace Demos. The finetuned Flan-T5 will be optimized to run fast locally.
        </p>
      </div>
    </div>
  </div>
</section>

<section class="hero is-small">
  <div class="hero-body">
    <div class="container is-max-desktop is-centered has-text-centered">
      <h2 class="title is-3">How does it work?</h2>
      <img src="static/images/tifa_webapproach.png">
      <div class="content has-text-justified">
        <p>
          (a) <b>Overview of how TIFA evaluates the faithfulness of a synthesized image.</b> TIFA uses a language model (LM), a question answering (QA) model, and a visual question answering (VQA) model. Given a text input, we generate several question-answer pairs with the LM and then filter them via the QA model. To evaluate the faithfulness of a synthesized image to the text input, a VQA model answers these visual questions using the image, and we check the answers for correctness.
        </p>
        <p>
          (b) <b>TIFA v1.0 benchmark.</b> While TIFA is applicable to any text prompt, to allow direct comparison across different studies, and for ease of use, we introduce the TIFA v1.0 benchmark, a repository of text inputs along with pre-generated question-answer pairs. To evaluate a text-to-image model, a user first produces the images for the text inputs in TIFA v1.0 and then performs VQA with our provided tools on generated images to compute TIFA.
        </p>
        <p>
          (c) <b>Our question-answer pair generation pipeline.</b> The whole pipeline can be executed via a single inference of GPT-3 via in-context learning. Given the text prompt, GPT-3 first extracts the elements and then generates two questions for each element. The GPT-3 output is then parsed and filtered by UnifiedQA.
        </p>

      </div>
    </div>
  </div>
</section>


<section class="hero is-small">
  <div class="hero-body">
    <div class="container is-max-desktop is-centered has-text-centered">
      <h2 class="title is-3">TIFA v1.0 Benchmark</h2>
      <img src="static/images/tifa_benchmark_new.png">
      <div class="content has-text-justified">
        <br>
        <p>
          TIFA v1.0 benchmark contains 4,081 text inputs sampled from MSCOCO, DrawBench, PartiPrompt, and PaintSkill. Each text input is paired with questions generated by GPT-3 and filtered by UnifiedQA, resulting in 25,829 questions altogether. The text inputs contain elements from 12 categories, as illustrated in the figure. We also show the most common elements from each category. In addition, we also show some example text inputs on the sides.
        </p>
      </div>
    </div>
  </div>
</section>



<section class="hero is-small">
  <div class="hero-body">
    <div class="container is-max-desktop is-centered has-text-centered">
      <h2 class="title is-3">Text-to-Image Model Leaderboard</h2>
      <img src="static/images/tifa_leaderboard.png"  width=80%>
      <div class="content has-text-justified">
        <p>
          We benchmarked 
        </p>
      </div>
    </div>
  </div>
</section>

<section class="hero is-small">
  <div class="hero-body">
    <div class="container is-max-desktop is-centered has-text-centered">
      <h2 class="title is-3">What are Stable Diffusion models struggling on?</h2>
      <img src="static/images/question_type.png">
      <div class="content has-text-justified">

        </p>
      </div>
    </div>
  </div>
</section>


<section class="hero is-small">
  <div class="hero-body">
    <div class="container is-max-desktop is-centered has-text-centered">
      <h2 class="title is-3">Composing multiple objects is difficult</h2>
      <img src="static/images/compositionality.png" width=60%>
      <div class="content has-text-justified">

        </p>
      </div>
    </div>
  </div>
</section>

<section class="hero is-small">
  <div class="hero-body">
    <div class="container is-max-desktop is-centered has-text-centered">
      <h2 class="title is-3">TIFA is more correlated with human judgments than CLIP</h2>
      <img src="static/images/tifa_compare.png" width=60%>
      <div class="content has-text-justified">

        </p>
      </div>
    </div>
  </div>
</section>





<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            This means you are free to borrow the <a
              href="https://github.com/nerfies/nerfies.github.io">source code</a> of this website,
            we just ask that you link back to this page in the footer.
            Please remember to remove the analytics code included in the header of the website which
            you do not want on your website.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
